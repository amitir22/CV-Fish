{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac986ed3",
   "metadata": {},
   "source": [
    "# Video Processing in a Sliding Window (Experiment)\n",
    "\n",
    "This notebook demonstrates reading a video using OpenCV and processing it **a few frames at a time**, keeping a queue of up to `batch_size` frames and processing it. \n",
    "Each time we add a new frame, if the queue is full, we drop the oldest frame. This effectively gives us a rolling/sliding window of frames.\n",
    "\n",
    "A degenerated usage of processing 1 frame per iteration can be achieved by initializing ProcessVideoExperiment with batch_size=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fb21d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you need to install opencv-python, uncomment and run:\n",
    "# !pip install opencv-python\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from video_batch_processor import VideoBatchProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a4af87",
   "metadata": {},
   "source": [
    "### Set Video Path and Batch Size\n",
    "- `video_path`: the path to your supported video file.\n",
    "- `batch_size`: how many frames to store in the sliding window.\n",
    "- `video_capture_object`: the object that provides frames to process. \n",
    "                          can be camera/file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3baf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"Workable Data/Processed/DPH0_Surface_TL.avi\"  # Replace with your actual video\n",
    "batch_size = 5  # Number of frames in the sliding window\n",
    "video_capture_object = cv.VideoCapture(video_path)\n",
    "\n",
    "if not video_capture_object.isOpened():\n",
    "        raise IOError(f\"Cannot open video file: {video_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dc748d",
   "metadata": {},
   "source": [
    "### Setup Hyper-Parameters\n",
    "- `super_pixel_dimensions`: a tuple of (x_size, y_size)\n",
    "- `frame_window_size`: the queue size of the moving window of frames.\n",
    "- `flow_farneback_params`: the params used for the motion detection algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4eb135",
   "metadata": {},
   "outputs": [],
   "source": [
    "super_pixel_dimensions = (2, 2)  # can be modified\n",
    "frame_window_size = 5\n",
    "flow_farneback_params = {\n",
    "    \"flow\": None,\n",
    "    \"pyr_scale\": 0.5,\n",
    "    \"levels\": 3,\n",
    "    \"winsize\": 15,\n",
    "    \"iterations\": 3,\n",
    "    \"poly_n\": 5,\n",
    "    \"poly_sigma\": 1.2,\n",
    "    \"flags\": 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff6c3eb",
   "metadata": {},
   "source": [
    "### Process Function\n",
    "We'll define a simple function to illustrate what you might do with each batch (window) of frames.\n",
    "- Here, we just print out how many frames are in the current window.\n",
    "- You could replace this with custom logic (e.g., saving images, running inference, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09d4c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame_window(frames: np.array, call_index: int):\n",
    "    # TODO:\n",
    "    # version 1.0:\n",
    "    #   call 1 simple processing function to extract data from frame windows.\n",
    "    # version 2.0:\n",
    "    #   in this function i will call different processing functions as \n",
    "    #   a series of processing units in a way that i can connect output\n",
    "    #   of 1 processing unit to another.\n",
    "    #   this will allow the testing of complex analysis ideas.\n",
    "    print(f'call index: {call_index}, len: {len(frames)}, shape: {frames[0].shape}')\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497699c2",
   "metadata": {},
   "source": [
    "### Main Loop\n",
    "Now we'll create an instance of `VideoBatchProcessor` and repeatedly call `next_batch()` until we reach the end of the video.\n",
    "On each iteration, we pass the resulting frames to `process_frame_window()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "184473eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished processing the video.\n"
     ]
    }
   ],
   "source": [
    "processor = VideoBatchProcessor(video_path, batch_size)\n",
    "call_index = 0\n",
    "\n",
    "try:\n",
    "    # Keep processing frames streamlined\n",
    "    while True:\n",
    "        frames_window = processor.next_batch()\n",
    "\n",
    "        if frames_window is None: \n",
    "            break # No more frames\n",
    "\n",
    "        call_index += 1\n",
    "\n",
    "        process_frame_window(frames_window, call_index)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during processing: {e}\")\n",
    "finally:\n",
    "    processor.close()\n",
    "    print(\"\\nFinished processing the video.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
